{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2ac4d1-59c6-4e02-ad28-1d190032628c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark import SparkConf, SparkContext\\nconf = SparkConf().setAppName(\"Barcelona_Bike_Sharing\")\\nsc = SparkContext(conf = conf)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName(\"Barcelona_Bike_Sharing\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64fe0a15-d686-4d26-a52c-02d35bf2bf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65a965c-da9f-43f7-9a88-73a715d617c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fac299-7029-49af-8fda-8d692f185174",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputStations = \"In_data/stations.csv\"\n",
    "inputRegister = \"In_data/registerSample.csv\"\n",
    "outputPath = \"Out_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3205e8a3-e667-4d98-9bc7-8f3a05850bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputRDD = sc.textFile(inputRegister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7081e86d-96a0-4dfb-8c03-60203163da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove the header and the lines with #free slots=0 && #used slots=0\n",
    "def filterFunc(line):\n",
    "    # Remove header\n",
    "    if line.startswith('s'):\n",
    "        return False\n",
    "    else:\n",
    "        fields = line.split(\"\\t\")\n",
    "        usedSlots = int(fields[2])\n",
    "        freeSlots = int(fields[3])\n",
    "\n",
    "        if freeSlots != 0 or usedSlots != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9657e2be-afb8-45a4-b162-3c816a6e31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredRDD = inputRDD.filter(filterFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d646c0e-60ac-454e-a9bc-fb845f628fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filteredRDD.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368e99d7-cc18-4f98-9063-64dda1eb8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def checkFull(line):\n",
    "    # station\\ttimestamp\\tused\\tfree\n",
    "    # 1\\t2008-05-15 12:01:00\\t0\\t18\n",
    "    fields = line.split(\"\\t\")\n",
    "    stationId = fields[0]\n",
    "    freeSlots = int(fields[3])\n",
    "    timestamp = fields[1]\n",
    "    \n",
    "    datetimeObject = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")    \n",
    "    dayOfTheWeek = datetimeObject.strftime(\"%A\")\n",
    "    hour = datetimeObject.hour\n",
    "\n",
    "    if freeSlots == 0:\n",
    "        # The station is full\n",
    "        countTotReadingsTotFull = (1, 1)\n",
    "    else:\n",
    "        countTotReadingsTotFull = (1, 0)\n",
    "        \n",
    "    return ((stationId, dayOfTheWeek, hour), countTotReadingsTotFull)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a353f2-168a-424b-8127-aa52fc12873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each line to a pair of (StationId_DayOfTheWeek_Hour, (1,1) if the station is full & (1,0) if the station is not full)\n",
    "stationWeekDayHour = filteredRDD.map(checkFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8b90731-f6ae-46ef-beba-7c9f64c160d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of readings and \"full\" readings for each key\n",
    "stationWeekDayHourCounts = stationWeekDayHour.reduceByKey(lambda p1, p2: (p1[0]+p2[0], p1[1]+p2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "556f2e36-30b0-4106-987d-ec90eeb36c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute criticality for each key\n",
    "stationWeekDayHourCriticality = stationWeekDayHourCounts.mapValues(lambda value: value[1]/value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cefb6db2-116d-45f6-bd2d-678927f007b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stationWeekDayHourCriticality.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c33582a0-b03f-41e5-95b1-78eb3b6d8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the pairs with criticality > threshold\n",
    "threshold = 0.4\n",
    "selectedPairs = stationWeekDayHourCriticality.filter(lambda pair: pair[1]>= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7fcbcfa-3e41-496a-bb23-f253330af582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(selectedPairs.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "339d57ec-ce03-4e37-a4a2-532e70ec9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new PairRDD with\n",
    "# key = station Id\n",
    "# value = DayOfTheWeek, Hour, Criticality\n",
    "stationTimeslotCrit = selectedPairs.map(lambda StationWeekdayHourCrit:\\\n",
    "                                        (StationWeekdayHourCrit[0][0],\\\n",
    "                                         (StationWeekdayHourCrit[0][1], StationWeekdayHourCrit[0][2],\\\n",
    "                                          StationWeekdayHourCrit[1])\\\n",
    "                                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ffd838c-7369-45d1-9cee-7ffd8cb0c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compare criticality between two timeslots\n",
    "def compareCriticality(timeslotCrit1, timeslotCrit2):\n",
    "\n",
    "    weekday1 = timeslotCrit1[0]\n",
    "    weekday2 = timeslotCrit2[0]\n",
    "    \n",
    "    hour1 = timeslotCrit1[1]\n",
    "    hour2 = timeslotCrit2[1]\n",
    "\n",
    "    crit1 = timeslotCrit1[2]\n",
    "    crit2 = timeslotCrit2[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if crit1>crit2 or \\\n",
    "    (crit1==crit2 and hour1<hour2) or \\\n",
    "    (crit1==crit2 and hour1==hour2 and weekday1<weekday2):\n",
    "        return timeslotCrit1\n",
    "    else:\n",
    "        return timeslotCrit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6a0924d-321d-4a68-9388-6e9f1a36845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRDD = stationTimeslotCrit.reduceByKey(compareCriticality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ac772be-fba1-4172-8a63-789dda09abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return pair of(stationId, (long, lat))\n",
    "def extractStationLongLat(line):\n",
    "    fields = line.split(\"\\t\")\n",
    "    \n",
    "    return (fields[0], (fields[1] ,fields[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "967dd7eb-7898-4844-92d8-0b1b4caac959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the location of the stations\n",
    "stationLocation = sc.textFile(inputStations).map(extractStationLongLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f4866d-0724-4eb4-919f-29840dea8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the locations with the \"critical\" stations\n",
    "resultLocations = resultRDD.join(stationLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4781d6b-d993-4049-885a-0954c6addb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a string that represents a KML marker\n",
    "def formatKMLMarker(pair):\n",
    "    # input\n",
    "    # (stationId, ( (weekday, hour, criticality), (long, lat) ) )\n",
    "    stationId = pair[0]\n",
    "    \n",
    "    weekday = pair[1][0][0]\n",
    "    hour = pair[1][0][1]\n",
    "    criticality = pair[1][0][2]\n",
    "    coordinates = pair[1][1][0]+\",\"+pair[1][1][1]\n",
    "    \n",
    "    result = \"<Placemark><name>\" + stationId + \"</name>\" + \"<ExtendedData>\"\\\n",
    "    + \"<Data name=\\\"DayWeek\\\"><value>\" + weekday + \"</value></Data>\"\\\n",
    "    + \"<Data name=\\\"Hour\\\"><value>\" + str(hour) + \"</value></Data>\"\\\n",
    "    + \"<Data name=\\\"Criticality\\\"><value>\" + str(criticality) + \"</value></Data>\"\\\n",
    "    + \"</ExtendedData>\" + \"<Point>\" + \"<coordinates>\" + coordinates + \"</coordinates>\"\\\n",
    "    + \"</Point>\" + \"</Placemark>\"\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02cbf478-e3e9-495b-9b98-2c527fb71b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string containing the description of a marker, in the KML format, for each\n",
    "# sensor and the associated information\n",
    "resultKML = resultLocations.map(formatKMLMarker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ff4de9c-8ddf-4552-bb34-a9487442b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of partitions to 1 for resultKML and store it in the output folder\n",
    "resultKML.coalesce(1).saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eccfaac5-a942-482b-9d96-ffee9d6fffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resultKML.take(10))  # This will show the first 10 elements in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6e4ccfc-d2dc-4440-808e-b0eadd1a5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_output = \"Out_data/part-00000\"\n",
    "\n",
    "# Read Spark output\n",
    "with open(spark_output, \"r\") as f:\n",
    "    spark_data = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c837ad23-f7ae-438e-a720-b990b34cfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch Out_data/output.kml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d08d6715-ddf1-4e96-a61b-727db7173018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write into a KML file\n",
    "with open(\"Out_data/output.kml\", \"w\") as f2:\n",
    "    f2.write(\n",
    "        \"\"\"<kml xmlns=\"http://www.opengis.net/kml/2.2\"><Document>\"\"\"\n",
    "        + spark_data +\n",
    "        \"\"\"</Document></kml>\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce6953-a44b-4338-9595-23967cb75d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "kernel_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
